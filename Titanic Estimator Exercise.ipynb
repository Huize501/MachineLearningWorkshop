{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own model using Datasets and Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erwinh/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "# Lets first check what Tensorflow version we are using. \n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your Data First\n",
    "\n",
    "**To Do**\n",
    "\n",
    "- *Get your csv files for training and testing from [Kaggle](https://www.kaggle.com/c/titanic/data).*\n",
    "- *Make sure you store your data somewhere so that you can use it. \n",
    "\n",
    "If this doesn't work get the data from here:\n",
    "- Bucket [Train](https://storage.googleapis.com/erwinh-ml-demo/data/titanic/TitanicTrain.csv).\n",
    "- Bucket [Test](https://storage.googleapis.com/erwinh-ml-demo/data/titanic/TitanicTest.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the path to the CSV's\n",
    "\n",
    "file_train = \n",
    "file_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always check the data\n",
    "\n",
    "df = pd.read_csv(file_train)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the metadata that we are going to use for training our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define header names\n",
    "HEADER = []\n",
    "\n",
    "#Setup default values for missing\n",
    "DEFAULTS = []\n",
    "\n",
    "#Numeric Feature Names\n",
    "NUMERIC_FEATURE_NAMES = []\n",
    "\n",
    "#Setup Categorical Feature Names\n",
    "CATEGORICAL_FEATURE_NAMES = []\n",
    "\n",
    "#Variable with all the feature names\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "#Set Target\n",
    "TARGET_NAME = 'Survived'\n",
    "\n",
    "TARGET_VALUES = [1,0]\n",
    "\n",
    "#Unused features\n",
    "UNUSED_FEATURE_NAMES = set(HEADER) - set(FEATURE_NAMES) - set([TARGET_NAME])\n",
    "\n",
    "#Print features + unused features\n",
    "print(\"Header: {}\".format(HEADER))\n",
    "print(\"Numeric Features: {}\".format(NUMERIC_FEATURE_NAMES))\n",
    "print(\"Categorical Features: {}\".format(CATEGORICAL_FEATURE_NAMES))\n",
    "print(\"Target: {} - labels: {}\".format(TARGET_NAME, TARGET_VALUES))\n",
    "print(\"Unused Features: {}\".format(UNUSED_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a inpute function that we can re-use for different models and different datasets. For this we use the Dataset API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(file_path, repeat_count=1):\n",
    "  #Write here your input function\n",
    "  return batch_features, batch_labels\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feature_columns():\n",
    "  \n",
    "  # Write here the code to create your feature columns\n",
    "  #Example: Age=tf.feature_column.numeric_column('Age')\n",
    "\n",
    "  features_columns = [] # Return the name of the feature columns\n",
    "  \n",
    "  return features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = create_feature_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to build a Machine Learning model. Here we will initiate our estimator and train it using the training dataset that we have created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify here the hidden units and other metadata needed. \n",
    "\n",
    "num_hidden_units =[]  # Setup your architecture\n",
    "number_classes = 2\n",
    "directory = \"./Checkpoints/checkpoints_tutorial17-2/\" # Can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize your classifier here and define the parameters you want to use. \n",
    "\n",
    "classifier = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train your classifier\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to check how our model performs on our test dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will create a new input function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test input function \n",
    "\n",
    "def test_input_fn(file_path, repeat_count=1):\n",
    "  # Write here the code for the test input function\n",
    "  return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our model using the examples contained in FILE_TEST\n",
    "# Return value will contain evaluation_metrics such as: loss & average_loss\n",
    "evaluate_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(file_path, False, 4))\n",
    "print(\"Evaluation results\")\n",
    "for key in evaluate_result:\n",
    "    print(\"   {}, was: {}\".format(key, evaluate_result[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
