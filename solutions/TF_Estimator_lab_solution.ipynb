{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TF Estimator lab solution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RxwFuWdbVblt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1> Create TensorFlow DNN model </h1>\n",
        "\n",
        "This notebook illustrates:\n",
        "<ol>\n",
        "<li> Creating a model using the high-level Estimator API \n",
        "</ol>"
      ]
    },
    {
      "metadata": {
        "id": "NVakrNWiVblv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BUCKET = 'erwinh-public-data/babyweight/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8oq5zZqVblz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['BUCKET'] = BUCKET"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RYyX1KNnVbl1",
        "colab_type": "code",
        "outputId": "0b71d647-3eea-4c2d-8650-cea206dd243c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "gsutil -m cp gs://${BUCKET}**.csv ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://erwinh-public-data/babyweight/eval.csv...\n",
            "Copying gs://erwinh-public-data/babyweight/train.csv...\n",
            "/ [0/2 files][    0.0 B/  1.9 MiB]   0% Done                                    \r/ [0/2 files][    0.0 B/  1.9 MiB]   0% Done                                    \r/ [1/2 files][  1.9 MiB/  1.9 MiB]  99% Done                                    \r/ [2/2 files][  1.9 MiB/  1.9 MiB] 100% Done                                    \r\n",
            "Operation completed over 2 objects/1.9 MiB.                                      \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lb2vVRwQVbl3",
        "colab_type": "code",
        "outputId": "b218dbf3-1d98-4693-dc53-b0cdc0489334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash \n",
        " \n",
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "babyweight\n",
            "eval.csv\n",
            "sample_data\n",
            "train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WPfovOQbVbl5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Create TensorFlow model using TensorFlow's Estimator API </h2>\n",
        "<p>\n",
        "First, write an input_fn to read the data."
      ]
    },
    {
      "metadata": {
        "id": "vVcckaQrVbl6",
        "colab_type": "code",
        "outputId": "8dd209a5-c181-4138-9c71-b167ae7ea02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lVPUIPR7Vbl8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Determine CSV, label, and key columns\n",
        "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,key'.split(',')\n",
        "LABEL_COLUMN = 'weight_pounds'\n",
        "KEY_COLUMN = 'key'\n",
        "\n",
        "# Set default values for each CSV column\n",
        "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], ['nokey']]\n",
        "TRAIN_STEPS = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhds4vJlVbl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an input function reading a file using the Dataset API\n",
        "# Then provide the results to the Estimator API\n",
        "def read_dataset(filename, mode, batch_size = 512):\n",
        "  def _input_fn():\n",
        "    def decode_csv(value_column):\n",
        "      columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
        "      features = dict(zip(CSV_COLUMNS, columns))\n",
        "      label = features.pop(LABEL_COLUMN)\n",
        "      return features, label\n",
        "    \n",
        "    # Create list of files that match pattern\n",
        "    file_list = tf.gfile.Glob(filename)\n",
        "\n",
        "    # Create dataset from file list\n",
        "    dataset = (tf.data.TextLineDataset(file_list)  # Read text file\n",
        "                 .map(decode_csv))  # Transform each elem by applying decode_csv fn\n",
        "      \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        num_epochs = None # indefinitely\n",
        "        dataset = dataset.shuffle(buffer_size=10*batch_size)\n",
        "    else:\n",
        "        num_epochs = 1 # end-of-input after this\n",
        " \n",
        "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYB7mmYPVbmA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, define the feature columns"
      ]
    },
    {
      "metadata": {
        "id": "Wl1ciaRnVbmB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define feature columns\n",
        "def get_categorical(name, values):\n",
        "  return tf.feature_column.indicator_column(\n",
        "    tf.feature_column.categorical_column_with_vocabulary_list(name, values))\n",
        "\n",
        "def get_cols():\n",
        "  # Define column types\n",
        "  return [\\\n",
        "          get_categorical('is_male', ['True', 'False', 'Unknown']),\n",
        "          tf.feature_column.numeric_column('mother_age'),\n",
        "          get_categorical('plurality',\n",
        "                      ['Single(1)', 'Twins(2)', 'Triplets(3)',\n",
        "                       'Quadruplets(4)', 'Quintuplets(5)','Multiple(2+)']),\n",
        "          tf.feature_column.numeric_column('gestation_weeks')\n",
        "      ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8a50NIiVbmD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To predict with the TensorFlow model, we also need a serving input function. We will want all the inputs from our user."
      ]
    },
    {
      "metadata": {
        "id": "6HqiHYI6VbmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create serving input function to be able to serve predictions later using provided inputs\n",
        "def serving_input_fn():\n",
        "    feature_placeholders = {\n",
        "        'is_male': tf.placeholder(tf.string, [None]),\n",
        "        'mother_age': tf.placeholder(tf.float32, [None]),\n",
        "        'plurality': tf.placeholder(tf.string, [None]),\n",
        "        'gestation_weeks': tf.placeholder(tf.float32, [None])\n",
        "    }\n",
        "    features = {\n",
        "        key: tf.expand_dims(tensor, -1)\n",
        "        for key, tensor in feature_placeholders.items()\n",
        "    }\n",
        "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZgJhS6eVbmF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create estimator to train and evaluate\n",
        "def train_and_evaluate(output_dir):\n",
        "  EVAL_INTERVAL = 300\n",
        "  run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,\n",
        "                                      keep_checkpoint_max = 3)\n",
        "  estimator = tf.estimator.DNNRegressor(\n",
        "                       model_dir = output_dir,\n",
        "                       feature_columns = get_cols(),\n",
        "                       hidden_units = [64, 32],\n",
        "                       config = run_config)\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "                       input_fn = read_dataset('train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
        "                       max_steps = TRAIN_STEPS)\n",
        "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "                       input_fn = read_dataset('eval.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
        "                       steps = None,\n",
        "                       start_delay_secs = 60, # start evaluating after N seconds\n",
        "                       throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
        "                       exporters = exporter)\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Xz89KDqVbmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, train!"
      ]
    },
    {
      "metadata": {
        "id": "sN2a9KjLVbmI",
        "colab_type": "code",
        "outputId": "3486de83-d1df-46a9-b276-636e10c092be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1142
        }
      },
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "shutil.rmtree('babyweight_trained', ignore_errors = True) # start fresh each time\n",
        "train_and_evaluate('babyweight_trained')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'babyweight_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7accfbf9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into babyweight_trained/model.ckpt.\n",
            "INFO:tensorflow:loss = 1788.5157, step = 1\n",
            "INFO:tensorflow:global_step/sec: 31.3048\n",
            "INFO:tensorflow:loss = 632.6079, step = 101 (3.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.8\n",
            "INFO:tensorflow:loss = 588.8674, step = 201 (3.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1827\n",
            "INFO:tensorflow:loss = 561.65076, step = 301 (3.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3528\n",
            "INFO:tensorflow:loss = 644.1932, step = 401 (3.656 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3496\n",
            "INFO:tensorflow:loss = 614.7511, step = 501 (3.527 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6095\n",
            "INFO:tensorflow:loss = 612.761, step = 601 (3.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.8311\n",
            "INFO:tensorflow:loss = 594.26965, step = 701 (3.727 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.6111\n",
            "INFO:tensorflow:loss = 540.05334, step = 801 (3.762 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.2863\n",
            "INFO:tensorflow:loss = 565.02997, step = 901 (3.800 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into babyweight_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-17-09:26:54\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-17-09:26:55\n",
            "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.1271113, global_step = 1000, label/mean = 7.224725, loss = 547.293, prediction/mean = 7.2252536\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: babyweight_trained/model.ckpt-1000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
            "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>}\n",
            "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>}\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py:1018: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Pass your op to the equivalent parameter main_op instead.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: babyweight_trained/export/exporter/temp-b'1539768415'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 551.1207.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jrac6rPCVbmK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When I ran it, the final lines of the output (above) were:\n",
        "<pre>\n",
        "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.2693067, global_step = 1000, loss = 635.9226\n",
        "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
        "INFO:tensorflow:Assets added to graph.\n",
        "INFO:tensorflow:No assets to write.\n",
        "INFO:tensorflow:SavedModel written to: babyweight_trained/export/exporter/temp-1517899936/saved_model.pb\n",
        "</pre>\n",
        "The exporter directory contains the final model and the final RMSE (the average_loss) is 1.2693067"
      ]
    },
    {
      "metadata": {
        "id": "8Kj8qMxyVbmR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2017-2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
      ]
    }
  ]
}